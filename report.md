# Web Info Lab 2 - 实体/关系抽取

[TOC]

<center><h5>PB18000058 丁垣天<br/> PB18000028 邱子悦</h5></center>

## 1 实验目的

## 2 实验简介

本次实验采用两种不同的思路来完成关系抽取和实体识别的任务，并比较它们效果上的差异。两种方法的大题思路如下：

* 直接分类方法：直接将整个问题作为一个分类问题实现，即使用某种特定的分类算法（本实验采用`distilbert` 算法），把每句话分类成不同的关系类型（如 `Component-Whole`） 。
* 实体抽取 + 依存树方法：先对实体进行抽取，并选择两个最相关的实体，然后提取这两个实体在依存树上的路径，然后将路径放入分类模型进行分类。即

$$
实体抽取 \to 构建依存树并搜索两实体的路径 \to 放入分类模型分类
$$

具体过程参考[实验过程](## 4 实验过程)

## 3 实验说明


实验目录结构

```python
exp2                        # 根目录
├── dataset                
│   ├── test.txt            # 测试数据集
│   └── train.txt           # 训练数据集
├── models                  
│   ├── distilbert-classify # 分类模型
│   ├── distilbert-deps     # 基于依存树的分类模型
│   └── distilbert-ner      # 命名实体识别模型
├── outputs                
│   ├── output1.txt         # 直接分类方法的输出
│   └── output2.txt         # 实体识别 + 依存树分类方法的输出
├── README.md               # 运行说明
├── report.md               # 实验报告
├── src
│   ├── dataset.py          # 读取数据集
│   ├── dependency.py       # 处理依存树
│   ├── models.py           # 模型的实现
└── train.ipynb             # 使用该notebook来进行训练
└── test.ipynb              # 使用该notebook来测试运行效果
```

## 4 实验过程

### 4.1 直接分类方法

由于本实验只要求在一个句子中找出最合适的一对关系，故可以直接最简单地采用文本分类的方法。下面介绍我们实现文本分类的具体思路。

#### 4.1.1 分类模型的选择

本实验要在一个句子中找出最合适的一对实体和它们之间的关系，但很多情况下难以确定哪一对实体更为合适，比如下面的例子：

```
Prior to the 4004, engineers built computers either from collections of chips or from discrete components.
```

助教在实验二在线评测说明中给出的关系抽取结果为：`Instrument-Agency&chips,engineers` ，但想要从这一句话的诸多实体对中选择出 `chips`和`engineers` 这一对实体是一件非常难以理解的事情，而一旦选择 `engineers` 和 `computers` 这一对实体，关系抽取的结果就应当为 `Product-Producer` 。从这个例子可以看出来，该问题具有很强的非线性性。**很难使用传统的机器学习方法（决策树、SVM、CRF）等方法求解，必须使用深度神经网络才能得到比较好的结果。**

但是另一方面，本次实验的数据集相对而言比较小，使用特别复杂的神经网络，非常容易产生过拟合，故为了防止过拟合，我们使用一下两个策略：

* 使用迁移学习，即使用已经训练好的模型辅助训练。
* 使用知识蒸馏模型，知识蒸馏模型往往具有层数比较少的网络和较少的参数，不容易引起过拟合。

所以我们选择非常知名的 `distilbert` 模型进行迁移学习，该模型拥有与 `BERT` 相似的效果，但使用了更浅的网络和更少的参数。可以帮助我们在该问题上达到一个比较好的效果（`validation 63%`）。

#### 4.1.2 `distilbert` 模型

https://arxiv.org/pdf/1910.01108.pdf

#### 4.1.3 模型的训练



### 4.2 实体抽取 + 依存树方法

该方法的整体思路如下：
$$
实体抽取 \to 构建依存树并搜索两实体的路径 \to 放入分类模型分类
$$

#### 4.2.1 训练实体抽取模型

#### 4.2.2 提取依存树和路径

#### 4.2.3 训练分类模型

## 5 实验结果








